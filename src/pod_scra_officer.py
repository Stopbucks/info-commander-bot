
#---------------------------------------------------------------
# æœ¬ç¨‹å¼ç¢¼ï¼šsrc/pod_scra_officer.py v4.5 (S-Plan è‡ªé©æ€§åµå¯Ÿç‰ˆ)
# ä»»å‹™ï¼šå¯¦ä½œå³æ™‚ API é¤˜é¡åµæ¸¬ã€æ°¸ä¹…æ¨¡å¼è¨˜æ†¶ã€åŠæœˆåˆè‡ªå‹•å›æ­¸
# æµç¨‹ï¼šJitter å•Ÿå‹• -> æŸ¥è©¢ ScraperAPI é¤˜é¡ -> æ±ºå®šæ­¦å™¨ -> åŸ·è¡Œä»»å‹™
#---------------------------------------------------------------
import os, requests, urllib.parse, time, re, urllib3, random
from supabase import create_client, Client
from bs4 import BeautifulSoup
from datetime import datetime, timezone

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def get_scraperapi_balance(api_key):
    """æŠ€è¡“ç”¨èªï¼šå³æ™‚é™æ¸¬ã€‚ç›´æ¥å¾ ScraperAPI å¸³æˆ¶ç«¯é»ç²å–æœ€æ–°å‰©é¤˜é»æ•¸"""
    try:
        res = requests.get(f"https://api.scraperapi.com/account?api_key={api_key}", timeout=10)
        if res.status_code == 200:
            data = res.json()
            # å‰©é¤˜é»æ•¸ = ç¸½é¡åº¦ - å·²ä½¿ç”¨
            return data['request_limit'] - data['request_count']
    except Exception as e:
        print(f"âš ï¸ [é™æ¸¬å¤±æ•—] ç„¡æ³•ç²å– ScraperAPI é¤˜é¡: {e}")
    return 78  # å¤±æ•—æ™‚å›å‚³å®‰å…¨ä¿å®ˆå€¼

class StrategyManager:
    """æˆ°ç•¥ç®¡ç†å™¨ï¼šè² è²¬é›™è»Œåˆ‡æ›ã€æ¨¡å¼æŒä¹…åŒ–åŠæœˆåˆè‡ªå‹•æ ¡æº–"""
    def __init__(self, supabase: Client, user_mode: str, scra_key: str):
        self.sb = supabase
        self.scra_key = scra_key
        
        # è‹¥ä½¿ç”¨è€…æ‰‹å‹•å¾é¢æ¿é¸æ“‡æ¨¡å¼ï¼Œå‰‡å°‡è©²è¨­å®šå¯«å…¥ Supabase å¯¦ç¾ã€Œæ°¸ä¹…è¨˜æ†¶ã€
        if user_mode in ["MODE_1", "MODE_2", "AUTO"]:
            self.sb.table("api_budget_control").update({"mode_status": user_mode}).eq("id", "ZENROWS").execute()
            print(f"ğŸ’¾ [æˆ°ç•¥å­˜æª”] ç•¶å‰æ¨¡å¼å·²é–å®šç‚ºï¼š{user_mode}")
        
        self.config = self._load_config()

    def _load_config(self):
        res = self.sb.table("api_budget_control").select("*").eq("id", "ZENROWS").execute()
        data = res.data[0]
        
        # æ¨¡å¼äºŒèˆ‡è‡ªé©æ€§æ ¡æº–ï¼šæ¯æœˆ 1 è™Ÿå¼·åˆ¶æ¢å¾© 1000 é»ï¼Œä¸¦å›æ­¸ AUTO æ¨¡å¼
        if datetime.now().day == 1 and data['last_reset_date'] != str(datetime.now().date()):
            update_fields = {
                "balance": 1000, 
                "mode_status": "AUTO", 
                "last_reset_date": str(datetime.now().date())
            }
            self.sb.table("api_budget_control").update(update_fields).eq("id", "ZENROWS").execute()
            data.update(update_fields)
            print("ğŸ“… [æœˆåˆæ ¡æº–] é»æ•¸é‡ç½®å®Œæˆï¼Œæˆ°ç•¥å›æ­¸ AUTO æ¨¡å¼ã€‚")
        return data

    def get_provider(self):
        # å„ªå…ˆè®€å–è³‡æ–™åº«å­˜æª”çš„æ¨¡å¼
        saved_mode = self.config.get("mode_status", "AUTO")
        
        if saved_mode == "MODE_1": return "SCRAPERAPI"
        if saved_mode == "MODE_2": return "ZENROWS"
        
        # è‹¥ç‚º AUTOï¼Œå‰‡æ ¹æ“š ScraperAPI å³æ™‚é»æ•¸é€²è¡Œè‡ªé©æ€§åˆ‡æ›
        scra_balance = get_scraperapi_balance(self.scra_key)
        print(f"ğŸ“Š ScraperAPI å³æ™‚åº«å­˜ï¼š{scra_balance} é»")
        
        # é¢¨éšªæé†’ï¼šè‹¥ ScraperAPI ä½æ–¼ 50 é»ï¼Œè‡ªå‹•åˆ‡æ›è‡³ ZenRows å‚™æ´
        if scra_balance < 50:
            return "ZENROWS"
        return "SCRAPERAPI"

    def deduct_zenrows(self):
        # æ¨¡æ“¬æ‰£é»ï¼šæ ¹æ“š ZenRows è¦å‰‡ï¼ŒPodbay æ¸²æŸ“æ‰£é™¤ 25 é»
        new_balance = max(0, self.config['balance'] - 25)
        self.sb.table("api_budget_control").update({"balance": new_balance}).eq("id", "ZENROWS").execute()
        print(f"ğŸ“‰ [æ‰£é»] ZenRows å‰©é¤˜é ä¼°ï¼š{new_balance}")

def run_scra_officer():
    # æˆ°è¡“ Jitterï¼šéš¨æ©Ÿå•Ÿå‹•å»¶é² 10~40 åˆ†é˜
    start_delay = random.randint(600, 2400)
    print(f"ğŸ•’ [æˆ°è¡“ç­‰å¾…] å•Ÿå‹•éš¨æ©Ÿä¼‘çœ  {start_delay//60} åˆ†é˜...")
    time.sleep(start_delay)

    sb_url = os.environ.get("SUPABASE_URL")
    sb_key = os.environ.get("SUPABASE_KEY")
    scra_key = os.environ.get("SCRAP_API_KEY")
    zen_key = os.environ.get("ZENROWS_API_KEY")
    # è®€å– GitHub é¢æ¿è¼¸å…¥
    user_mode = os.environ.get("STRATEGY_MODE", "AUTO")

    if not all([sb_url, sb_key, scra_key, zen_key]):
        print("âŒ [è³‡å®‰è­¦å ±] ç¼ºå°‘å¿…è¦ç’°å¢ƒè®Šæ•¸ã€‚")
        return

    supabase: Client = create_client(sb_url, sb_key)
    manager = StrategyManager(supabase, user_mode, scra_key)
    
    # å€å¡ŠåŒ–è¨­è¨ˆï¼šæ¯æ¬¡è™•ç†ä¸è¶…é 3 ç­†ï¼Œç¶­è­·è³‡æºå®¹æ˜“
    missions = supabase.table("mission_queue").select("*").eq("scrape_status", "pending").limit(3).execute()
    
    if not missions.data:
        print("â˜• ç›®å‰ç„¡å¾…è™•ç†ä»»å‹™ã€‚")
        return

    for index, target in enumerate(missions.data):
        # ä»»å‹™é–“éš¨æ©Ÿé–“éš” 3~10 åˆ†é˜ï¼Œæ¨¡æ“¬çœŸäººç€è¦½
        if index > 0:
            interval = random.randint(180, 600)
            print(f"â³ [ä»»å‹™é–“éš”] ä¼‘çœ  {interval//60} åˆ†é˜...")
            time.sleep(interval)

        task_id = target['id']
        podbay_slug = target.get('podbay_slug') or "bloomberg-businessweek"
        final_mp3_url = ""
        
        # å‘¼å«è‡ªé©æ€§åˆ¤æ–·
        provider = manager.get_provider()
        target_page = f"https://podbay.fm/p/{podbay_slug}"
        print(f"ğŸ¯ [è™•ç†ä¸­] {target['episode_title'][:20]}... æ¡ç”¨ï¼š{provider}")

        try:
            if provider == "ZENROWS":
                params = {'api_key': zen_key, 'url': target_page, 'js_render': 'true', 'premium_proxy': 'true'}
                resp = requests.get('https://api.zenrows.com/v1/', params=params, timeout=60)
                manager.deduct_zenrows()
            else:
                api_url = f"https://api.scraperapi.com?api_key={scra_key}&url={urllib.parse.quote(target_page)}&render=true"
                resp = requests.get(api_url, timeout=60)

            soup = BeautifulSoup(resp.text, 'html.parser')
            audio_meta = soup.find('meta', property=re.compile(r'(og:audio|twitter:player:stream)'))
            if audio_meta:
                final_mp3_url = audio_meta.get('content')
            else:
                mp3_link = soup.find('a', href=re.compile(r'\.mp3'))
                if mp3_link: final_mp3_url = mp3_link['href']

        except Exception as e:
            print(f"âš ï¸ [æŠ“å–ç•°å¸¸]ï¼š{str(e)}")

        if final_mp3_url:
            try:
                update_data = {
                    "audio_url": final_mp3_url,
                    "scrape_status": "success",
                    "status": "pending",
                    "created_at": datetime.now(timezone.utc).isoformat()
                }
                supabase.table("mission_queue").update(update_data).eq("id", task_id).execute()
                print(f"âœ… [å…¥åº«æˆåŠŸ] é–€ç¥¨ç™¼æ”¾ã€‚")
            except Exception as e:
                print(f"âŒ [å¯«å…¥å¤±æ•—]ï¼š{str(e)}")

if __name__ == "__main__":
    run_scra_officer()