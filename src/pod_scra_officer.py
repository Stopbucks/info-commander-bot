
#---------------------------------------------------------------
#---------------------------------------------------------------
# æœ¬ç¨‹å¼ç¢¼ï¼šsrc/pod_scra_officer.py v5.0 (S-Plan æ¨¡çµ„åŒ–è§£è€¦ç‰ˆ)
# ä»»å‹™ï¼šæˆ°ç•¥èª¿åº¦ã€æ¨¡å¼æŒä¹…åŒ–ã€æœˆåˆè‡ªå‹•æ ¡æº–ã€å‘¼å«å¤–éƒ¨ Scanner
#---------------------------------------------------------------#---------------------------------------------------------------
# æœ¬ç¨‹å¼ç¢¼ï¼šsrc/pod_scra_officer.py v6.0 (å…µåŠ›é‡ç·¨æ±ºæˆ°ç‰ˆ)
# ä»»å‹™ï¼šMode 3 æ›ç­ Hasdataã€WebScrap è½‰è·åµè¨Šå®˜ã€æˆ°ç•¥æŒä¹…åŒ–
#---------------------------------------------------------------
import os, requests, urllib.parse, time, re, urllib3, random
from supabase import create_client, Client
from bs4 import BeautifulSoup
from datetime import datetime, timezone
from pod_scra_scanner import fetch_html 

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- å€å¡Šï¼šæ–°å¢ Hasdata èˆ‡ WebScrap ç‰¹ç¨®åŠŸèƒ½ ---
def investigate_final_url(url, webscrap_key):
    """
    ğŸ•µï¸ [åµè¨Šå®˜è¡Œå‹•] WebScrap å°ˆå±¬ä»»å‹™ï¼šè¿½æŸ¥è§£ææœ€çµ‚ç¶²å€ã€‚
    """
    # åˆ©ç”¨ WebScrap å¼·å¤§çš„è§£æèƒ½åŠ›ï¼Œè¿½è¹¤é‡å®šå‘å¾Œçš„æœ€çµ‚ MP3 åº§æ¨™ã€‚
    print(f"ğŸ•µï¸ [åµè¨Šä¸­] WebScrap æ­£åœ¨è¿½è¹¤æœ€çµ‚ç›®æ¨™...")
    # é€™è£¡å¯ä¸²æ¥ WebScrap å°ˆç”¨çš„è§£æé‚è¼¯
    return url # ç¯„ä¾‹å›å‚³

class StrategyManager:
    def __init__(self, supabase: Client, user_mode: str, scra_key: str):
        self.sb = supabase
        self.scra_key = scra_key
        # ä¸€è¡Œè¨»è§£ï¼šå°‡æ‰‹å‹•é¸å®šçš„æˆ°ç•¥æ¨¡å¼æŒä¹…åŒ–å­˜å…¥è³‡æ–™åº«ï¼Œå¯¦ç¾è·¨ session è¨˜æ†¶ã€‚
        if "MODE_" in user_mode or user_mode == "AUTO":
            self.sb.table("api_budget_control").update({"mode_status": user_mode}).eq("id", "ZENROWS").execute()
            print(f"ğŸ’¾ [æˆ°ç•¥å­˜æª”] æŒ‡ä»¤å·²é–å®šï¼š{user_mode}")
        self.config = self._load_config()

    def _load_config(self):
        res = self.sb.table("api_budget_control").select("*").eq("id", "ZENROWS").execute()
        data = res.data[0]
        # æ¯æœˆ 1 è™ŸåŸ·è¡Œè‡ªå‹•æ ¡æº–ï¼Œå°‡æˆ°ç•¥æ¨¡å¼é‡ç½®ç‚º AUTO ç‹€æ…‹ã€‚
        if datetime.now().day == 1 and data['last_reset_date'] != str(datetime.now().date()):
            update_fields = {"balance": 1000, "mode_status": "AUTO", "last_reset_date": str(datetime.now().date())}
            self.sb.table("api_budget_control").update(update_fields).eq("id", "ZENROWS").execute()
            data.update(update_fields)
            print("ğŸ“… [æœˆåˆæ ¡æº–] å…¨è»å›æ­¸ AUTO æ¨¡å¼ã€‚")
        return data

    def get_action_plan(self):
        saved_mode = self.config.get("mode_status", "AUTO")
        
        # ğŸ¯ [æˆ°ç•¥è®Šæ›´] Mode 3 æ”¹ç”± HASDATA å‡ºå‹¤
        mode_map = {
            "MODE_1_Scrapi": "SCRAPERAPI",
            "MODE_2_Zenrows": "ZENROWS",
            "MODE_3_Hasdata": "HASDATA",  # Mode 3 æ­£å¼æ›´æ›ç‚º Hasdata éƒ¨éšŠã€‚
            "MODE_4_Scrapedo": "SCRAPEDO"
        }

        if saved_mode in mode_map:
            return mode_map[saved_mode]

        # AUTO æ¨¡å¼ä¸‹ï¼Œè‹¥é»æ•¸å……è¶³å‰‡å„ªå…ˆä½¿ç”¨ ScraperAPI
        scra_balance = get_scraperapi_balance(self.scra_key)
        if scra_balance > 80:
            return "SCRAPERAPI"
        else:
            return "ZENROWS"

    def deduct_points(self, provider):
        # æ ¹æ“šä¸åŒä¾›æ‡‰å•†ï¼Œæ‰£é™¤è³‡æ–™åº«ä¸­é ä¼°çš„ API é»æ•¸é¤˜é¡ã€‚
        if provider == "ZENROWS":
            new_balance = max(0, self.config['balance'] - 25)
            self.sb.table("api_budget_control").update({"balance": new_balance}).eq("id", "ZENROWS").execute()

def run_scra_officer():
    # ğŸš€ [è£œçµ¦æ›´æ–°] æ–°å¢ HASDATA é‡‘é‘°ï¼Œä¿ç•™ WEBSCRAP ä¾›åµè¨Šå®˜èª¿åº¦
    all_keys = {
        "SCRAPERAPI": get_secret("SCRAP_API_KEY"),
        "ZENROWS": get_secret("ZENROWS_API_KEY"),
        "HASDATA": get_secret("HASDATA_API_KEY"), # ç‚ºæ–°éƒ¨éšŠ Hasdata é…ç™¼å¯†é‘°ã€‚
        "WEBSCRAP": get_secret("WEBSCRAP_API_KEY"), # ä¿ç•™ WebScrap å¯†é‘°ä¾›ç‰¹å®šè§£æä»»å‹™èª¿ç”¨ã€‚
        "SCRAPEDO": get_secret("SCRAPEDO_API_KEY")
    }
    sb_url = get_secret("SUPABASE_URL")
    sb_key = get_secret("SUPABASE_KEY")
    user_mode = os.environ.get("STRATEGY_MODE", "AUTO")

    supabase: Client = create_client(sb_url, sb_key)
    manager = StrategyManager(supabase, user_mode, all_keys["SCRAPERAPI"])

    missions = supabase.table("mission_queue").select("*").eq("scrape_status", "pending").limit(3).execute()

    for target in missions.data:
        task_id = target['id']
        podbay_slug = str(target.get('podbay_slug') or "").strip()
        provider = manager.get_action_plan()
        target_page = f"https://podbay.fm/p/{podbay_slug}"

        try:
            # ä¸€è¡Œè¨»è§£ï¼šå‘¼å«å¤–éƒ¨æƒæå™¨ï¼Œä¸¦å‚³éç•¶å‰æ±ºç­–çš„ä¾›æ‡‰å•†èˆ‡å¯†é‘°åº«ã€‚
            resp = fetch_html(provider, target_page, all_keys)
            manager.deduct_points(provider)

            if resp and resp.status_code == 200:
                soup = BeautifulSoup(resp.text, 'html.parser')
                # ... (ä¸­é–“è§£æé‚è¼¯ä¸è®Š) ...
                
                # ä¸€è¡Œè¨»è§£ï¼šå¦‚æœæŠ“åˆ°çš„ URL éœ€è¦é€²éšåµè¨Šï¼Œåœ¨æ­¤è™•å–šé†’ WebScrap åµè¨Šå®˜ã€‚
                # final_mp3_url = investigate_final_url(final_mp3_url, all_keys["WEBSCRAP"])

                update_data = {
                    "audio_url": final_mp3_url,
                    "scrape_status": "success",
                    "used_provider": provider, 
                    "status": "pending"
                }
                supabase.table("mission_queue").update(update_data).eq("id", task_id).execute()
        except Exception as e:
            print(f"âš ï¸ [ç¨‹åºç•°å¸¸]ï¼š{str(e)}")

# æ­¤è™•éœ€å®šç¾© get_secret ä»¥æ”¯æ´æ··åˆè®€å–é‚è¼¯ã€‚
def get_secret(key): return os.environ.get(key)

if __name__ == "__main__":
    run_scra_officer()