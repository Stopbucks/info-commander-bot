
#---------------------------------------------------------------
# æœ¬ç¨‹å¼ç¢¼ï¼špodcast_scra_officer.py v2.12 (é«˜ CP å»£åŸŸæå–ç‰ˆ)
# ä¿®æ­£ï¼šå–æ¶ˆä¸»é æ¸²æŸ“(çœé»æ•¸)ã€å»£åŸŸæƒæ MP3 æ¨™ç±¤ã€å®‰å…¨å‚™æ´
#---------------------------------------------------------------

import os, requests, urllib.parse, time, re, urllib3
from supabase import create_client, Client
from bs4 import BeautifulSoup

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def run_scra_officer():
    sb_url = os.environ.get("SUPABASE_URL")
    sb_key = os.environ.get("SUPABASE_KEY")
    scra_key = os.environ.get("SCRAP_API_KEY")
    supabase: Client = create_client(sb_url, sb_key)

    missions = supabase.table("mission_queue").select("*").eq("scrape_status", "pending").limit(2).execute()
    if not missions.data: return

    for target in missions.data:
        task_id = target['id']
        raw_title = target['episode_title']
        podbay_slug = target.get('podbay_slug') or "bloomberg-businessweek"
        final_mp3_url = ""

        # --- æˆ°å ´ä¸€ï¼šPodbay è¼•é‡åµå¯Ÿ ---
        try:
            program_home = f"https://podbay.fm/p/{podbay_slug}"
            # ğŸš€ å„ªåŒ– 1ï¼šä¸»é ä¸ä½¿ç”¨ render=trueï¼Œç¯€çœé»æ•¸ [cite: 2026-02-16]
            home_url = f"https://api.scraperapi.com?api_key={scra_key}&url={urllib.parse.quote(program_home)}"
            resp = requests.get(home_url, timeout=30, verify=False)
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            ep_tag = soup.find('a', href=re.compile(r'/p/.+/e/.*'))
            if ep_tag:
                full_ep_url = f"https://podbay.fm{ep_tag['href']}"
                print(f"âœ… [ç™¼ç¾é›†æ•¸]ï¼š{full_ep_url}")
                
                # ğŸš€ å„ªåŒ– 2ï¼šåƒ…åœ¨é›†æ•¸é ä½¿ç”¨æ¸²æŸ“æå– MP3 [cite: 2026-02-16]
                ep_encoded = urllib.parse.quote(full_ep_url)
                ep_res = requests.get(f"https://api.scraperapi.com?api_key={scra_key}&url={ep_encoded}&render=true", timeout=60)
                ep_soup = BeautifulSoup(ep_res.text, 'html.parser')
                
                # ğŸš€ å„ªåŒ– 3ï¼šå»£åŸŸæƒæå¤šç¨®éŸ³è¨Šæ¨™ç±¤ (og, twitter, or a-href) [cite: 2026-02-16]
                audio_meta = ep_soup.find('meta', property=re.compile(r'(og:audio|twitter:player:stream)'))
                if audio_meta:
                    final_mp3_url = audio_meta.get('content')
                else:
                    # æœ€å¾Œä¸€æï¼šç›´æ¥åœ¨ HTML è£¡æ‰¾ä»»ä½•åŒ…å« .mp3 çš„é€£çµ
                    mp3_link = ep_soup.find('a', href=re.compile(r'\.mp3'))
                    if mp3_link: final_mp3_url = mp3_link['href']
        except: pass

        # --- æœ€çµ‚çµç®— ---
        if final_mp3_url:
            supabase.table("mission_queue").update({"podbay_url": final_mp3_url, "scrape_status": "success"}).eq("id", task_id).execute()
            print(f"ğŸš€ [å¤§æ·] æˆåŠŸå–å¾—é–€ç¥¨ï¼š{final_mp3_url[:40]}...")
        else:
            supabase.table("mission_queue").update({"scrape_status": "failed"}).eq("id", task_id).execute()
            print(f"âŒ [å¤±æ•—] æ¨™é¡Œï¼š{raw_title[:20]}")
        
        time.sleep(3)

if __name__ == "__main__":
    run_scra_officer()