#---------------------------------------------------------------
# æœ¬ç¨‹å¼ç¢¼ç‚ºï¼špodcast_scra_officer.py 
# ç‰ˆæœ¬ï¼šv2.6 é›™æˆ°å ´å¯¦æˆ°ç‰ˆ (Podbay + Listen Notes)
#---------------------------------------------------------------

#---------------------------------------------------------------
# æœ¬ç¨‹å¼ç¢¼ï¼špodcast_scra_officer.py v2.9 (ä¸»é ç›´å…¥ + JS æ¸²æŸ“ç ´è§£ç‰ˆ)
# ç‰¹è‰²ï¼šè·³éå…¨ç¶²æœå°‹ï¼Œç›´æ¥ç©ºé™ç¯€ç›®ä¸»é ï¼Œé–‹å•Ÿ ScraperAPI é«˜ç´šæ¸²æŸ“ [cite: 2026-02-16]
#---------------------------------------------------------------

import os, requests, urllib.parse, time, re, urllib3
from supabase import create_client, Client
from bs4 import BeautifulSoup

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def run_scra_officer():
    sb_url = os.environ.get("SUPABASE_URL")
    sb_key = os.environ.get("SUPABASE_KEY")
    scra_key = os.environ.get("SCRAP_API_KEY")
    supabase: Client = create_client(sb_url, sb_key)

    # ğŸš€ é ˜å–ä»»å‹™ (åµå¯Ÿå…µ Vercel å·²å°‡ podbay_slug å¡«å…¥ mission_queue)
    missions = supabase.table("mission_queue").select("*").eq("scrape_status", "pending").limit(2).execute()
    if not missions.data: return

    for target in missions.data:
        task_id = target['id']
        raw_title = target['episode_title']
        # ğŸ’¡ è‹¥ç„¡é è¨­ Slugï¼Œå‰‡ä½¿ç”¨ç¯€ç›® ID (ä¾‹å¦‚ 1691284824) [cite: 2026-02-16]
        podbay_slug = target.get('podbay_slug') or "bloomberg-businessweek" 
        final_mp3_url = ""

        # --- æˆ°è¡“å‹•ä½œï¼šç›´æ¥ç©ºé™ç¯€ç›®ä¸»é  ---
        # ğŸš€ ç­–ç•¥ï¼šä½¿ç”¨ render=true ç ´è§£æ‚¨çœ‹åˆ°çš„ã€Œè¼‰å…¥åœˆåœˆã€åçˆ¬èŸ² [cite: 2026-02-16]
        program_home = f"https://podbay.fm/p/{podbay_slug}"
        print(f"ğŸ¯ [ç›´æ¥ç©ºé™] é€²å…¥ç¯€ç›®ä¸»é ï¼š{program_home}")
        
        try:
            # é–‹å•Ÿ render=true æœƒç­‰å¾… JavaScript åŠ è¼‰å®Œç•¢ (æ¶ˆè€—ç´„ 5-10 é») [cite: 2026-02-16]
            render_url = f"https://api.scraperapi.com?api_key={scra_key}&url={program_home}&render=true"
            resp = requests.get(render_url, timeout=60, verify=False)
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            # åœ¨ä¸»é å…§å°‹æ‰¾æœ€æ¥è¿‘åŸå§‹æ¨™é¡Œçš„é›†æ•¸é€£çµ [cite: 2026-02-16]
            # ğŸ’¡ S-Plan æŠ€å·§ï¼šåªè¦é é¢ä¸Šçš„æ–‡å­—åŒ…å«æ¨™é¡Œçš„å‰ 10 å€‹å­—å³åˆ¤å®šå‘½ä¸­
            match_word = raw_title[:10]
            ep_tag = soup.find('a', string=re.compile(match_word, re.I)) or soup.find('a', href=re.compile(r'/p/.+/e/.*'))
            
            if ep_tag:
                full_ep_url = f"https://podbay.fm{ep_tag['href']}"
                print(f"âœ… [ç²¾ç¢ºå‘½ä¸­] æ‰¾åˆ°é›†æ•¸é é¢ï¼š{full_ep_url}")
                
                # é€²å…¥é›†æ•¸é æå– (é›†æ•¸é é€šå¸¸ä¸éœ€è¦ render)
                ep_res = requests.get(f"https://api.scraperapi.com?api_key={scra_key}&url={full_ep_url}")
                final_mp3_url = BeautifulSoup(ep_res.text, 'html.parser').find('meta', property="og:audio")['content']
        except Exception as e:
            print(f"âš ï¸ æ”»å …ç™¼ç”Ÿæ•…éšœï¼š{str(e)}")

        # --- å›å¡«çµæœ ---
        if final_mp3_url:
            supabase.table("mission_queue").update({"podbay_url": final_mp3_url, "scrape_status": "success"}).eq("id", task_id).execute()
            print(f"ğŸš€ [è§£ç¢¼æˆåŠŸ] MP3 ç¶²å€å·²å…¥åº«ã€‚")
        else:
            supabase.table("mission_queue").update({"scrape_status": "failed"}).eq("id", task_id).execute()
        
        time.sleep(3)

if __name__ == "__main__":
    run_scra_officer()