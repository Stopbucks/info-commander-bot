
#---------------------------------------------------------------
# æœ¬ç¨‹å¼ç¢¼ï¼špodcast_scra_officer.py v2.11 (æ¸²æŸ“æ”»å … + LN å‚™æ´ç‰ˆ)
# ä¿®æ­£ï¼šå¼·åˆ¶ URL ç·¨ç¢¼ã€å…©æ®µå¼æ¸²æŸ“ç ´é˜²ã€å®‰å…¨æ¬„ä½æå–
#---------------------------------------------------------------

import os, requests, urllib.parse, time, re, urllib3
from supabase import create_client, Client
from bs4 import BeautifulSoup

# ğŸš€ å±è”½ä¸å¿…è¦çš„å®‰å…¨è­¦å ±
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def run_scra_officer():
    sb_url = os.environ.get("SUPABASE_URL")
    sb_key = os.environ.get("SUPABASE_KEY")
    scra_key = os.environ.get("SCRAP_API_KEY")
    supabase: Client = create_client(sb_url, sb_key)

    # 1. é ˜å–ä»»å‹™ (è™•ç† pending ç‹€æ…‹çš„ä»»å‹™)
    missions = supabase.table("mission_queue").select("*").eq("scrape_status", "pending").limit(2).execute()
    if not missions.data: return

    for target in missions.data:
        task_id = target['id']
        raw_title = target['episode_title']
        # ğŸ’¡ è‹¥æœ‰ Podbay Slug æˆ– Listen Notes IDï¼Œå°‡å„ªå…ˆä½¿ç”¨
        podbay_slug = target.get('podbay_slug') or "bloomberg-businessweek"
        ln_id = target.get('listen_notes_id') or "bloomberg-businessweek-bloomberg-yn5Mm7jSGBe"
        final_mp3_url = ""

        print(f"\nğŸ“¡ [é–‹å§‹æ”»å …] ç›®æ¨™æ¨™é¡Œï¼š{raw_title[:30]}...")

        # --- æˆ°å ´ä¸€ï¼šPodbay æ¸²æŸ“æå– (æ¶ˆè€—è¼ƒä½ï¼Œå„ªå…ˆæ¸¬è©¦) ---
        try:
            program_home = f"https://podbay.fm/p/{podbay_slug}"
            # ğŸš€ é—œéµï¼šå°‡æ•´å€‹ç¶²å€é€²è¡Œç·¨ç¢¼ï¼Œä¸¦é–‹å•Ÿ render=true
            podbay_api_url = f"https://api.scraperapi.com?api_key={scra_key}&url={urllib.parse.quote(program_home)}&render=true"
            print(f"ğŸ¯ [Podbay æ¸²æŸ“ä¸­]...")
            resp = requests.get(podbay_api_url, timeout=60, verify=False)
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            # åœ¨æ¸²æŸ“å¾Œçš„é é¢ä¸­å°‹æ‰¾é›†æ•¸é€£çµ
            ep_tag = soup.find('a', href=re.compile(r'/p/.+/e/.*'))
            if ep_tag:
                full_ep_url = f"https://podbay.fm{ep_tag['href']}"
                print(f"âœ… [é–å®š Podbay é›†æ•¸]ï¼š{full_ep_url}")
                
                # å†æ¬¡æ¸²æŸ“é›†æ•¸é ä»¥æå– MP3
                encoded_ep = urllib.parse.quote(full_ep_url)
                ep_res = requests.get(f"https://api.scraperapi.com?api_key={scra_key}&url={encoded_ep}&render=true", timeout=60)
                ep_soup = BeautifulSoup(ep_res.text, 'html.parser')
                audio_tag = ep_soup.find('meta', property="og:audio")
                if audio_tag: final_mp3_url = audio_tag.get('content')
        except Exception as e:
            print(f"âš ï¸ Podbay æ•…éšœï¼š{str(e)[:50]}")

        # --- æˆ°å ´äºŒï¼šListen Notes å‚™æ´ (è‹¥ Podbay æ²’æŠ“åˆ°ï¼ŒåŸ·è¡Œé«˜éšç ´é˜²) ---
        if not final_mp3_url:
            print(f"ğŸ”„ [è½‰å‘å‚™æ´] å˜—è©¦å¾ Listen Notes æå–...")
            try:
                # ğŸ¯ ä½¿ç”¨æ‚¨æä¾›çš„ Podcast ID ç©ºé™
                ln_url = f"https://www.listennotes.com/podcasts/{ln_id}/"
                encoded_ln = urllib.parse.quote(ln_url)
                # ğŸš€ Listen Notes å° JS ä¾è³´æ¥µé‡ï¼Œå¿…é ˆé–‹å•Ÿ render=true
                ln_api_url = f"https://api.scraperapi.com?api_key={scra_key}&url={encoded_ln}&render=true"
                ln_resp = requests.get(ln_api_url, timeout=60, verify=False)
                ln_soup = BeautifulSoup(ln_resp.text, 'html.parser')
                
                # åœ¨æ¸²æŸ“å¾Œå°‹æ‰¾æœ€æ–°çš„éŸ³è»Œ
                audio_tag = ln_soup.find('meta', property="og:audio")
                if audio_tag: 
                    final_mp3_url = audio_tag.get('content')
                    print(f"ğŸ¯ [LN å®šä½æˆåŠŸ]")
            except Exception as e:
                print(f"âš ï¸ Listen Notes æ•…éšœï¼š{str(e)[:50]}")

        # --- å›å¡«çµæœ ---
        if final_mp3_url:
            supabase.table("mission_queue").update({"podbay_url": final_mp3_url, "scrape_status": "success"}).eq("id", task_id).execute()
            print(f"âœ… [æˆåŠŸå…¥åº«] é–€ç¥¨ï¼š{final_mp3_url[:40]}...")
        else:
            supabase.table("mission_queue").update({"scrape_status": "failed"}).eq("id", task_id).execute()
        
        time.sleep(5) # å»¶é•·å†·å»

if __name__ == "__main__":
    run_scra_officer()