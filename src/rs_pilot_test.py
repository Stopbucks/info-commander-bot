# =========================================================
# RS (Rescue-Standalone) ç¨ç«‹æ”»å …è…³æœ¬ - v2.0
# è·è²¬ï¼šä¸ä¾è³´ä»»ä½•å¤–éƒ¨ utilsï¼Œ ScraperAPI åŸ·è¡Œå¯¦æˆ°ä¸‹è¼‰Podbay.fm çš„ç¶²é åŸå§‹ç¢¼ã€‚
# =========================================================
import os
import requests
import feedparser
import random
import time

# ğŸš€ éš¨æ©Ÿä¼‘æ¯ï¼šç¢ºä¿å•Ÿå‹•æ™‚çš„æ“¬æ…‹å®‰å…¨æ€§ [cite: 2026-02-15]
time.sleep(random.uniform(3, 6))

def run_s_plan_integrated_test():
    """ğŸš€ [S-Plan æ•´åˆæ¸¬è©¦] å¾ RSS æå–æ¨™é¡Œ -> å‰å¾€ Podbay åµå¯Ÿç¶²å€"""
    api_key = os.environ.get('SCRAP_API_KEY', '').strip()
    
    # ğŸ“‹ æŒ‡æ®å®˜æä¾›çš„å…µåŠ›éƒ¨ç½²æ¸…å–® (JSON æ¨¡æ“¬)
    squad_targets = [
        {"name": "Odd Lots-Bloomberg", "url": "https://omnycontent.com/d/playlist/e73c998e-6e60-432f-8610-ae210140c5b1/8A94442E-5A74-4FA2-8B8D-AE27003A8D6B/982F5071-765C-403D-969D-AE27003A8D83/podcast.rss"},
        {"name": "FT - unhedged", "url": "https://feeds.acast.com/public/shows/6478a825654260001190a7cb"}
    ]

    print(f"ğŸ“¡ [S-Plan å•Ÿå‹•] æ­£åœ¨åŸ·è¡Œæ•´åˆåµå¯Ÿä»»å‹™...")

    for target in squad_targets:
        print(f"\n--- ğŸ›°ï¸ æ­£åœ¨è§£æ RSSï¼š{target['name']} ---")
        try:
            # Step 1: è§£æ RSS ç²å–æœ€æ–°é›†æ•¸è³‡è¨Š [cite: 2026-01-16]
            feed = feedparser.parse(target['url'])
            if not feed.entries:
                print(f"âŒ ç„¡æ³•è®€å– RSS å…§å®¹")
                continue
            
            latest_title = feed.entries[0].title
            print(f"ğŸ“ ç²å–æœ€æ–°é›†æ¨™é¡Œï¼š{latest_title[:40]}...")

            # Step 2: æ§‹é€  Podbay æœå°‹é€£çµ (æ¨¡æ“¬åµå¯Ÿå…µå°‹æ‰¾ç›®æ¨™) [cite: 2026-02-15]
            # ğŸ’¡ æŠ€å·§ï¼šå°‡æ¨™é¡Œæ”¾å…¥ Podbay æœå°‹ï¼ŒScraperAPI æœƒå¹«æˆ‘å€‘æ‹¿åˆ°æœå°‹çµæœé 
            search_query = latest_title.replace(" ", "+")
            podbay_search_url = f"https://podbay.fm/search?q={search_query}"
            
            # Step 3: ä½¿ç”¨ ScraperAPI åŸ·è¡Œç¶²é è§£å‰– (HTML æŠ“å–)
            proxy_url = f"http://scraperapi:{api_key}@proxy-server.scraperapi.com:8001"
            proxies = {"http": proxy_url, "https": proxy_url}
            headers = {"User-Agent": "Mozilla/5.0"}
            
            print(f"ğŸ” [é›²ç«¯åµå¯Ÿ] æ­£åœ¨é€é ScraperAPI å°‹æ‰¾é¡åƒé–€ç¥¨...")
            # ğŸš€ åŠ ä¸Š verify=False ä¿®å¾©ä¹‹å‰çš„ SSL å ±è­¦ [cite: 2026-02-15]
            resp = requests.get(podbay_search_url, proxies=proxies, headers=headers, timeout=30, verify=False)
            
            if resp.status_code == 200:
                print(f"âœ… [åµå¯Ÿå¤§æ·] æˆåŠŸå–å¾— Podbay æœå°‹çµæœï¼é é¢å¤§å°ï¼š{len(resp.text)//1024} KB")
                # é€™è£¡æˆ‘å€‘æš«æ™‚åªæª¢æ¸¬æ¨™ç±¤æ˜¯å¦å­˜åœ¨ï¼Œä½œç‚ºä¸‹ä¸€æ­¥ Selector çš„ä¾æ“š
                if latest_title[:10] in resp.text:
                    print(f"ğŸ¯ ç‹€æ…‹ï¼šå·²åœ¨ HTML ä¸­å®šä½åˆ°ç›®æ¨™é›†æ•¸ã€‚")
                else:
                    print(f"âš ï¸ è­¦å‘Šï¼šHTML ä¸­æœªç™¼ç¾åŒ¹é…æ¨™é¡Œï¼Œå¯èƒ½éœ€è¦æ›´ç²¾ç¢ºçš„æœå°‹ã€‚")
            else:
                print(f"âŒ [åµå¯Ÿå—é˜»] ç‹€æ…‹ç¢¼ï¼š{resp.status_code}")

        except Exception as e:
            print(f"ğŸ’¥ [æŠ€è¡“æ•…éšœ] è©²ç›®æ¨™åŸ·è¡Œå¤±æ•—: {str(e)[:60]}")

    print("\nğŸ [S-Plan éšæ®µæ¸¬è©¦çµæŸ]")

if __name__ == "__main__":
    run_s_plan_integrated_test()