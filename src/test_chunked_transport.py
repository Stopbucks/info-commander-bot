# ---------------------------------------------------------
# æœ¬ç¨‹å¼ç¢¼ï¼šsrc/test_chunked_transport.py v4.5 (ç´”ä»£ç†æ”»å …ç‰ˆ)
# è·è²¬ï¼šå¾ Supabase é ˜å– pending ä»»å‹™ -> é€é WebScraping.ai è§£æ -> å„²å­˜æœ€çµ‚ç¶²å€
# ---------------------------------------------------------
import os
import requests
from urllib.parse import quote
from supabase import create_client

# ä¸€è¡Œè¨»è§£ï¼šå»ºç«‹åŸºåœ°å°é€£ç·šã€‚
supabase = create_client(os.environ.get("SUPABASE_URL"), os.environ.get("SUPABASE_KEY"))

def run_scout_mission():
    # ä¸€è¡Œè¨»è§£ï¼šå¾è³‡æ–™åº«ç²å–åµå¯ŸæˆåŠŸä½†å°šæœªç²å–æœ€çµ‚åº§æ¨™çš„ä»»å‹™ã€‚
    tasks = supabase.table("mission_queue").select("*").eq("scrape_status", "success").eq("status", "pending").execute()
    
    for task in tasks.data:
        target_id = task['id']
        original_url = task['audio_url']
        
        print(f"ğŸ“¡ [é ˜å‘½æˆåŠŸ] æ­£åœ¨ç‚ºä»»å‹™ {target_id[:8]} æ¢è·¯...")
        
        # ä¸€è¡Œè¨»è§£ï¼šé€é WebScraping.ai ä»£ç†ç™¼å‡ºè«‹æ±‚ï¼Œå°è£ç›®æ¨™ç¶²å€ä»¥é¿é–‹åçˆ¬èŸ²ã€‚
        api_key = os.environ.get("WEBSCRAP_API_KEY")
        proxy_url = f"https://api.webscraping.ai/html?api_key={api_key}&url={quote(original_url)}&on_error=status&proxy=datacenter"
        
        try:
            # ä¸€è¡Œè¨»è§£ï¼šåŸ·è¡Œæ¨™é ­è«‹æ±‚ä»¥è¿½è¹¤ Redirectï¼Œç²å–æœ€çµ‚æª”æ¡ˆåº§æ¨™ã€‚
            resp = requests.head(proxy_url, allow_redirects=True, timeout=20)
            resolved_url = resp.url 

            # ä¸€è¡Œè¨»è§£ï¼šå°‡ç²å–çš„æœ€çµ‚ç¶²å€æ›´æ–°è‡³ resolved_url æ¬„ä½ä¸¦æ¨™è¨˜ç‚º resolved ç‹€æ…‹ã€‚
            supabase.table("mission_queue").update({
                "resolved_url": resolved_url,
                "scrape_status": "resolved"
            }).eq("id", target_id).execute()
            
            print(f"âœ… [æ¢è·¯å®Œç•¢] çœŸå¯¦åº§æ¨™å·²å›å­˜è‡³è³‡æ–™åº«ã€‚")
            
        except Exception as e:
            print(f"âŒ [æ¢è·¯å¤±æ•—] ä»»å‹™ {target_id[:8]} é­é‡æ””æˆª: {e}")

if __name__ == "__main__":
    run_scout_mission()