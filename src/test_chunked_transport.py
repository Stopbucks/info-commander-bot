# ---------------------------------------------------------
# æœ¬ç¨‹å¼ç¢¼ï¼šsrc/test_chunked_transport.py v4.7 (ç²¾æº–åº§æ¨™è§£ç¢¼ç‰ˆ)
# ä»»å‹™ï¼šæ¸¬è©¦ WebScraping.ai è§£ææœ€çµ‚ç¶²å€ä¸¦ã€ŒåŸåœ°æ›´æ–°ã€
# ---------------------------------------------------------
import os
import requests
from urllib.parse import quote
from supabase import create_client
from dotenv import load_dotenv

# ä¸€è¡Œè¨»è§£ï¼šè¼‰å…¥ç’°å¢ƒé…ç½®ä¸¦å»ºç«‹åŸºåœ°å°é€£ç·šã€‚
load_dotenv()
supabase = create_client(os.environ.get("SUPABASE_URL"), os.environ.get("SUPABASE_KEY"))

def run_scout_test():
    # ä¸€è¡Œè¨»è§£ï¼šé ˜å– 3 ç­†å¾…å‘½ç‰©è³‡é€²è¡Œè·³è½‰è¿½è¹¤æ¸¬è©¦ã€‚
    tasks = supabase.table("mission_queue").select("*").eq("scrape_status", "success").eq("status", "pending").limit(3).execute()
    
    if not tasks.data:
        print("â˜• [æˆ°å ´è§€å¯Ÿ] ç›®å‰ç„¡å¾…å‘½ç‰©è³‡ï¼Œæ¼”ç¿’å–æ¶ˆã€‚")
        return

    for task in tasks.data:
        target_id = task['id']
        original_url = task['audio_url']
        
        print(f"ğŸ“¡ [è§£æå•Ÿå‹•] ä»»å‹™ {target_id[:8]} æ­£åœ¨è¿½è¹¤è·³è½‰è·¯å¾‘...")
        
        # ä¸€è¡Œè¨»è§£ï¼šæ§‹å»º WebScraping.ai ä»£ç†è«‹æ±‚ã€‚
        api_key = os.environ.get("WEBSCRAP_API_KEY")
        # ğŸ¯ é—œéµä¿®æ­£ï¼šåŠ å…¥ on_error=status ç¢ºä¿èƒ½æ­£ç¢ºè¿½è¹¤é‡å®šå‘ã€‚
        proxy_url = f"https://api.webscraping.ai/html?api_key={api_key}&url={quote(original_url)}&on_error=status&proxy=datacenter"
        
        try:
            # 
            # ä¸€è¡Œè¨»è§£ï¼šä½¿ç”¨ GET ä¸¦é–‹å•Ÿ stream=Trueï¼Œåªæ‹¿ Headers ä¸ä¸‹è¼‰æª”æ¡ˆä¸»é«”ã€‚
            resp = requests.get(proxy_url, allow_redirects=True, timeout=30, stream=True)
            
            # ğŸ¯ æ ¸å¿ƒé‚è¼¯ä¿®æ­£ï¼š
            # WebScraping.ai çš„ API æœƒåœ¨ Header ä¸­å›å‚³ç›®æ¨™çš„æœ€çµ‚ç¶²å€ (é€šå¸¸æ˜¯ x-final-url)ã€‚
            # å¦‚æœ Header æ²’æä¾›ï¼Œæˆ‘å€‘å‰‡å– response è¨˜éŒ„ä¸­æœ€å¾Œä¸€æ¬¡è·³è½‰çš„ç¶²å€ã€‚
            final_resolved_url = resp.headers.get('x-final-url') or resp.url
            
            # ä¸€è¡Œè¨»è§£ï¼šé˜²å‘†æª¢æŸ¥ï¼Œå¦‚æœæ‹¿åˆ°çš„ä¾ç„¶æ˜¯ WebScraping.ai çš„ API ç¶²å€ï¼Œè¡¨ç¤ºè§£æä¸å®Œæ•´ã€‚
            if "webscraping.ai" in final_resolved_url:
                print(f"âš ï¸ [è§£æä¸å®Œå…¨] åƒ…æ‹¿åˆ° API ç¶²å€ï¼Œè·³éå¯«å…¥ã€‚")
                continue

            # ä¸€æ­¥æ›´æ–°ï¼šå°‡è§£æå¾Œçš„çœŸå¯¦ä¸‹è¼‰ç¶²å€è¦†è“‹å› audio_urlã€‚
            supabase.table("mission_queue").update({
                "audio_url": final_resolved_url,
                "scrape_status": "resolved" 
            }).eq("id", target_id).execute()
            
            print(f"âœ… [è§£ææˆåŠŸ] çœŸå¯¦åº§æ¨™å·²å¯«å…¥ï¼š{final_resolved_url[:60]}...")
            
            # ä¸€è¡Œè¨»è§£ï¼šé—œé–‰æµé€£ç·šï¼Œç¯€çœè³‡æºã€‚
            resp.close()
            
        except Exception as e:
            print(f"âŒ [è§£ææ””æˆª] ä»»å‹™ {target_id[:8]} å¤±æ•—: {e}")

if __name__ == "__main__":
    run_scout_test()