# ---------------------------------------------------------
# æœ¬ç¨‹å¼ç¢¼ç‚ºï¼šPodcast_monitorï¼Œè™•ç†ï¼šå‡ºå‹¤åˆ¤å®š, è·¯å¾‘é¸æ“‡, åµå¯Ÿè„ˆè¡
# Upstash é ç•™ï¼šå¦‚æ› Redisï¼Œæ”¹ log_scrapi_success å…§å®¹ï¼Œä¸éœ€æ”¹ Rescuer ä¸‹è¼‰è¿´åœˆã€‚
# remove line 363ï¼š"ip_masked": current_ip,
# ---------------------------------------------------------

import json
import os
import time
import math
import random  # ğŸš€ [è£œæª”ç”¨] éš¨æ©Ÿæ¨¡çµ„ï¼Œçµ¦äºˆ ID é€²è¡Œè£œæª”
from podcast_utils import PATH_CONFIG, mask_ip  # ğŸš€  å¼•å…¥å…±é€šå·¥å…·
from datetime import datetime, timezone, timedelta  # ğŸš€ æ™‚é–“è¨ˆç®—ç›´è§€[timedelta]

# --- âš™ï¸ ç³»çµ±å¸¸æ•¸é…ç½® ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
MONITOR_FILE = os.path.join(CURRENT_DIR, "podcast_monitor.json")


class MemoryManager:
    
    # --- [å¢åŠ  filename åƒæ•¸] ---
    def __init__(self, filename="podcast_monitor.json"):
        """ğŸš€ [è»é†«æ ¸å¿ƒ] æ”¯æ´å‹•æ…‹è¨˜æ†¶æª”æ¡ˆåˆ‡æ›ï¼Œå¯¦ç¾éƒ¨éšŠéš”é›¢ [cite: 2026-01-16]"""
        self.file_path = os.path.join(CURRENT_DIR, filename)
        self.data = self._load_data()
        self.lambda_constant = 0.0288  
        self.vault_limit = 8           
# ==============================================================================

    def record_incident_report(self, identity_hash, host, diag_data):
        """ğŸ›¡ï¸ [å–è­‰å„²å­˜] ç´€éŒ„ 403 ç†”æ–·æ™‚çš„æ·±åº¦è¨ºæ–·æ•¸æ“š [cite: 2026-02-03]"""
        if "incidents" not in self.data:
            self.data["incidents"] = []
        
        report = {
            "identity_hash": identity_hash,
            "host": host,
            "diagnostics": diag_data,
            "timestamp": time.time(),
            "iso_time": datetime.now(timezone.utc).isoformat()
        }
        
        # åƒ…ä¿ç•™æœ€è¿‘ 10 ç­†å–è­‰ç´€éŒ„ï¼Œé¿å…æª”æ¡ˆéå¤§
        self.data["incidents"] = ([report] + self.data["incidents"])[:10]
        self.save()
        print(f"ğŸ“Š [ç›£è¦–å™¨] æ·±åº¦å–è­‰æ•¸æ“šå·²å°å­˜ï¼Œä¾›å¾ŒçºŒåˆ†æã€‚")

    #---æœªä¾†å®‰å…¨ç¨½æ ¸ç¨ç«‹å€å¡Šï¼šå¯èˆ‡(def is_identity_safe)é€²è¡Œçµ±æ•´ã€‚---
    #---åˆ†å‰²åŸå‰‡æ­·æ™‚cookie(æ•¸ä½äººæ ¼)ã€å…±æ™‚æ€§IP(ä¾‹å¦‚åŒä¸€å¤©åœ°ç†ä½ç½®)ã€‚---
    def check_and_record_drift(self, path_id, current_country):
        """ğŸ›¡ï¸ æª¢æŸ¥åœ°ç†ä½ç§»ä¸¦å¯¦æ–½ç†”æ–·æ©Ÿåˆ¶ [cite: 2026-02-06]"""
        
        # ğŸš€ [æ’é™¤é‚è¼¯]ï¼šScraperAPI (RE) è·¯å¾‘è·³éåœ°ç†ä½ç§»ç¨½æ ¸
        if path_id == "RE":
            return True, "âœ… å°ˆæ¥­ä»£ç†è·¯å¾‘ (ScraperAPI)ï¼Œè·³éåœ°ç†ç¨½æ ¸ã€‚"
        
        path_key = f"drift_lock_{path_id}"
        now = time.time()
        
        # 1. åˆå§‹åŒ–è·¯å¾‘ç´€éŒ„
        if path_key not in self.data:
            self.data[path_key] = {"count": 0, "last_country": current_country, "lock_until": 0}

        record = self.data[path_key]

        # 2. æª¢æŸ¥æ˜¯å¦è™•æ–¼ç†”æ–·æœŸ
        if now < record["lock_until"]:
            return False, f"âš ï¸ è·¯å¾‘ {path_id} è™•æ–¼ä½ç§»ç†”æ–·ä¸­ï¼Œå‰©é¤˜ {int((record['lock_until']-now)/3600)} å°æ™‚ã€‚"

        # 3. æª¢æŸ¥æ™‚é–“é‡ç½® (3 å¤©å¾Œè‡ªå‹•æ­¸é›¶)
        if record["count"] > 0 and (now - record.get("last_incident_ts", 0)) > (3 * 24 * 3600):
            print(f"â™»ï¸ è·¯å¾‘ {path_id} ä½ç§»ç´€éŒ„å·²éæœŸï¼Œé‡ç½®è¨ˆæ•¸ã€‚")
            record["count"] = 0

        # 4. åˆ¤å®šåš´é‡ä½ç§» (åœ‹å®¶ç¢¼ä¸åŒ)
        if record["last_country"] and current_country != record["last_country"]:
            record["count"] += 1
            record["last_incident_ts"] = now
            print(f"ğŸš¨ [ä½ç§»è­¦å‘Š] è·¯å¾‘ {path_id} åµæ¸¬åˆ°åœ°ç†è®Šå‹• ({record['last_country']} -> {current_country})ï¼æ¬¡æ•¸: {record['count']}/3")
            
            if record["count"] >= 3:
                record["lock_until"] = now + (3 * 24 * 3600) # å°ç¦ 3 å¤©
                self.save()
                return False, f"âŒ ä½ç§»éæ–¼åš´é‡ï¼Œè·¯å¾‘ {path_id} å¼·åˆ¶ç¦é£› 3 å¤©ã€‚"
        
        # æ›´æ–°æœ€å¾Œä½ç½®ä¸¦å­˜æª”
        record["last_country"] = current_country
        self.save()
        return True, "âœ… åœ°ç†ç’°å¢ƒç©©å®šã€‚"

    def record_performance(self, host, latency, is_success):
        """ğŸ“ˆ [æ­·æ™‚æ€§åˆ†æ] ç´€éŒ„ä¼ºæœå™¨æ•ˆèƒ½åœ°åœ– (èšåˆç‰ˆ) è¶…é 7 å¤©çš„æ•¸æ“šè‡ªå‹•ç°¡åŒ–"""
        if "performance_map" not in self.data:
            self.data["performance_map"] = {}
            
        hour_key = datetime.now(timezone.utc).strftime("%H") # 00-23
        if host not in self.data["performance_map"]:
            self.data["performance_map"][host] = {}
            
        if hour_key not in self.data["performance_map"][host]:
            self.data["performance_map"][host][hour_key] = {"lat_sum": 0, "count": 0, "ok": 0}
            
        # æ›´æ–°èšåˆæ•¸æ“š (ç¯€çœç©ºé–“)
        stats = self.data["performance_map"][host][hour_key]
        stats["lat_sum"] += latency
        stats["count"] += 1
        if is_success: stats["ok"] += 1
        
        # ğŸ›¡ï¸ è¶…é 7 å¤©æˆ–ç­†æ•¸éå¤šæ™‚çš„è‡ªå‹•æ¸…ç† (Placeholder é‚è¼¯)
        self.save()

    def save(self):
        """ğŸš€ [æŒä¹…åŒ–] å°‡è¨˜æ†¶å¯«å›æœ¬åœ° JSON æª”æ¡ˆ"""
        try:
            with open(self.file_path, "w", encoding="utf-8") as f:
                json.dump(self.data, f, ensure_ascii=False, indent=4)
        except Exception as e:
            print(f"âš ï¸ å­˜æª”å¤±æ•—: {e}")


    def add_pending_mission(self, source_name, audio_url, mission_type="failed_retry"):
        """ğŸ“ å°‡ä»»å‹™åŠ å…¥æ´¾å·¥å–®ï¼Œä¸¦å¯¦æ–½é£½å’Œè­¦æˆ’æª¢æŸ¥ [cite: 2026-02-04]"""
        # 1. é˜²æ­¢é‡è¤‡æ›è™Ÿ
        if any(m["audio_url"] == audio_url for m in self.data["pending_missions"]):
            return False
            
        # 2. ğŸš€ [é£½å’Œè­¦æˆ’ç·š] ç¢ºä¿å–®ä¸€ç¯€ç›®å¾…è¾¦ä»»å‹™ä¸è¶…é 2 å€‹
        current_pending = sum(1 for m in self.data["pending_missions"] 
                             if m["source_name"] == source_name and m["status"] == "pending")
        if current_pending >= 2:
            print(f"âš ï¸ [è­¦æˆ’] {source_name} å¾…è¾¦ä»»å‹™éå¤šï¼Œè·³éæœ¬æ¬¡æ›è™Ÿä»¥ç¯€çœè³‡æºã€‚")
            return False
        
        # ğŸš€ [æœªä¾†å°å‘å‘½å] ä½¿ç”¨æ—¥æœŸæ¨™ç±¤å–ä»£éƒ¨åˆ†éš¨æ©Ÿæ•¸
        date_tag = datetime.now(timezone.utc).strftime("%Y%m%d")
        safe_name = source_name.replace(" ", "_").replace("'", "")
        task_id = f"task_{safe_name}_{date_tag}"
        
        new_task = {
            "id": task_id,
            "source_name": source_name,
            "audio_url": audio_url,
            "added_at": time.time(),
            "status": "pending",
            "mission_type": mission_type,  
            "retry_count": 0
        }
        
        self.data["pending_missions"].append(new_task)
        self.save()
        print(f"ğŸ“Œ [æ´¾å·¥å–®] ä»»å‹™å·²æ›è™Ÿï¼š{source_name} ({mission_type})")
        return True

    def verify_isp_consistency(self, path_id, current_org):
        """ğŸ›¡ï¸ æª¢æŸ¥ç•¶å‰ ISP æ˜¯å¦èˆ‡è©²è·¯å¾‘æ­·å²ç´€éŒ„ç›¸ç¬¦ (æ¨¡ç³Šæ¯”å°ç‰ˆ) """
        last_org = self.data.get("last_recon", {}).get("org", "Unknown")
        if last_org == "Unknown": return True
        
        # ğŸ›¡ï¸ åªè¦ä¸»è¦ä¾›æ‡‰å•†åç¨±å‰ 3 ä½ä¸€è‡´ï¼Œå³è¦–ç‚ºåŒæº (æ‡‰å°åç¨±å¾®èª¿)
        return last_org[:3].upper() == current_org[:3].upper()
    

    def clean_expired_missions(self, days=7):
        """ğŸ§¹ æ¸…ç†è¶…é 7 å¤©ä¸”å·²å®Œæˆæˆ–éæœŸçš„ä»»å‹™"""
        limit_ts = time.time() - (days * 24 * 3600)
        original_count = len(self.data["pending_missions"])
        
        # åƒ…ä¿ç•™ 7 å¤©å…§çš„ä»»å‹™ï¼Œæˆ–ç‹€æ…‹ç‚º pending çš„é‡è¦ä»»å‹™
        self.data["pending_missions"] = [
            m for m in self.data["pending_missions"] 
            if m["added_at"] > limit_ts or m["status"] == "pending"
        ]
        
        if len(self.data["pending_missions"]) < original_count:
            print(f"ğŸ§¹ [ç›£è¦–å™¨] å·²æ¸…ç† {original_count - len(self.data['pending_missions'])} ç­†éæœŸä»»å‹™ã€‚")
            self.save()

    def check_scrapi_heavy_limit(self):
        """ğŸ›¡ï¸ å¯¦æ–½ ScraperAPI åš´æ ¼é™é¡å¯©æ ¸ (2+3+5 åŸå‰‡)"""
        now = time.time()
        # åˆå§‹åŒ–ç´€éŒ„
        if "scrapi_history" not in self.data:
            self.data["scrapi_history"] = []
            
        # æ¸…æ´— 48 å°æ™‚å‰çš„èˆŠç´€éŒ„
        self.data["scrapi_history"] = [ts for ts in self.data["scrapi_history"] 
                                       if now - ts < (48 * 3600)]
        
        # è¨ˆç®— 24h èˆ‡ 48h æˆåŠŸé‡
        count_24h = sum(1 for ts in self.data["scrapi_history"] if now - ts < (24 * 3600))
        count_48h = len(self.data["scrapi_history"])
        
        # åˆ¤å®šå…¬å¼: 24h < 3 ä¸” 48h < 5
        is_safe = (count_24h < 3 and count_48h < 5)
        return is_safe, count_24h, count_48h

    def log_scrapi_success(self):
        """ğŸ“ ç•¶ ScraperAPI æ•‘æ´æˆåŠŸæ™‚ï¼Œç´€éŒ„æ™‚é–“é»"""
        if "scrapi_history" not in self.data:
            self.data["scrapi_history"] = []
        self.data["scrapi_history"].append(time.time())
        self.save() # ğŸš€ ç¢ºä¿ç´€éŒ„ç«‹å³å¯«å›é›²ç«¯
        print("ğŸ“Š [ç›£è¦–å™¨] ScraperAPI é…é¡å·²æ›´æ–°ï¼ˆ+1 æˆåŠŸç´€éŒ„ï¼‰ã€‚")

    # --------- å®šä½é»ï¼šç´€éŒ„ Github æ•‘æ´æ¬¡æ•¸ä½¿ç”¨ ---------
    def log_github_rescue_success(self):
        """ğŸ“ ç•¶ GitHub æ•‘æ´æˆåŠŸæ™‚ï¼Œç´€éŒ„æ™‚é–“é»"""
        if "github_rescue_log" not in self.data:
            self.data["github_rescue_log"] = []
        self.data["github_rescue_log"].append(time.time())
        self.save() # ğŸš€ ç«‹å³å¯«å›é›²ç«¯ï¼ŒåŒæ­¥é…é¡ç‹€æ…‹
        print("ğŸ“Š [ç›£è¦–å™¨] GitHub æ•‘æ´é…é¡å·²æ›´æ–°ï¼ˆ+1 æˆåŠŸç´€éŒ„ï¼‰ã€‚")

    # =========================================================
    # ğŸ§¬ [æ ¸å¿ƒæ¨¡çµ„] æ•¸ä½äººæ ¼èˆ‡æŒ‡ç´‹åŒ¹é… (Persona & Footprint)
    # =========================================================

    def update_identity_vault(self, identity_state):
        """ğŸ§¬ [å­˜å…¥] åŒæ­¥æ•¸ä½äººæ ¼ï¼Œä¸¦ç®¡ç†å‹•æ…‹è¶³è·¡åº«ï¼ˆIP èˆ‡ Cookies å°æ¥ï¼‰"""
        target_hash = identity_state.get('identity_hash', 'unknown')
        h = f"id_{target_hash}"
        
        if h not in self.data["domains"]:
            self.data["domains"][h] = {"footprint_vault": [], "failures": []}
            
        target_vault = self.data["domains"][h].get("footprint_vault", [])
        current_ip = identity_state.get("ip")

        new_footprint = {
            "ip": current_ip,
            "masked_ip": current_ip,
            "org": identity_state.get("org"),
            "cookies": identity_state.get("cookies"),
            "timestamp": time.time()
        }

        # ğŸ›¡ï¸ æª¢æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒ IPï¼Œæœ‰çš„è©±æ›´æ–°ï¼Œç„¡å‰‡æ–°å¢è‡³é¦–ä½
        existing_idx = next((i for i, f in enumerate(target_vault) if f["ip"] == current_ip), None)
        if existing_idx is not None:
            target_vault[existing_idx] = new_footprint
        else:
            target_vault.insert(0, new_footprint)

        # âœ‚ï¸ ç¶­æŒå‹•æ…‹ä¸Šé™ (ç›®å‰ç‚º 8 ç­†) [cite: 2026-02-06]
        self.data["domains"][h]["footprint_vault"] = target_vault[:self.vault_limit]
        self.save()

    def match_best_footprint(self, identity_hash, current_ip):
        """ğŸ” [è®€å–] å°‹æ‰¾èˆ‡ç•¶å‰ IP åŒ¹é…çš„æ­·å²ç´€éŒ„ (æ•¸ä½äººæ ¼é‡å¡‘çš„æ ¸å¿ƒ)"""
        h = f"id_{identity_hash}"
        vault = self.data["domains"].get(h, {}).get("footprint_vault", [])
        
        # ğŸ’¡ ç²¾æº–æ¯”å°ï¼šåªæœ‰ç•¶å‰çš„ IP åœ¨æ­·å²ç´€éŒ„ä¸­ï¼Œæ‰å›å¡«å°æ‡‰çš„ Cookies
        match = next((f for f in vault if f["ip"] == current_ip), None)
        
        if match:
            print(f"ğŸ¯ [äººæ ¼é‡å¡‘] ç™¼ç¾åŒ¹é… IPï¼š{mask_ip(current_ip)}ï¼Œæº–å‚™è¼‰å…¥å°ˆå±¬ Cookiesã€‚")
            return match["cookies"]
        
        return None
    # =========================================================
    # ğŸ•µï¸ [è·¯å¾‘å¯©è¨ˆ] IP é£„ç§»åˆ†æå·¥å…· [cite: 2026-02-03]
    # =========================================================

    def get_last_known_ip(self, path_id):
        """ğŸ” å–å¾—è©²è·¯å¾‘ä¸Šä¸€æ¬¡æˆåŠŸåµå¯Ÿçš„ IP"""
        history = self.data.get("path_history", {}).get(str(path_id), [])
        return history[0] if history else None # è¿”å›æœ€æ–°çš„ç´€éŒ„

    def count_unique_ips(self, path_id, current_ip):
        """ğŸ“Š çµ±è¨ˆè©²è·¯å¾‘å‡ºç¾éå¤šå°‘ç¨®ä¸åŒçš„å‡ºå£ IP"""
        if "path_history" not in self.data: self.data["path_history"] = {}
        pid_str = str(path_id)
        
        if pid_str not in self.data["path_history"]:
            self.data["path_history"][pid_str] = []
            
        history = self.data["path_history"][pid_str]
        
        # ğŸ’¡ è‹¥ç•¶å‰ IP ä¸åœ¨æ­·å²ä¸­ï¼Œå‰‡åŠ å…¥æ­·å²æ¸…å–® (å»é‡çµ±è¨ˆ)
        if current_ip not in history:
            history.insert(0, current_ip) # ç½®é ‚æœ€æ–° IP
            # é™åˆ¶æ­·å²é•·åº¦ç‚º 20 ç­†ï¼Œé¿å…ç´€éŒ„éå¤š
            self.data["path_history"][pid_str] = history[:20]
            
        return len(set(history)) # è¿”å›ç¨ç‰¹ IP çš„ç¸½æ•¸

    def reload(self):
        """ğŸš€ ç•¶ GCP ä¸‹è¼‰å®Œæœ€æ–°è¨˜æ†¶å¾Œï¼Œå¼·åˆ¶é‡è¼‰æ•¸æ“šè‡³è¨˜æ†¶é«”"""
        self.data = self._load_data()
        print("ğŸ§  [è¨˜æ†¶é‡è¼‰] å·²åŒæ­¥æœ€æ–°çš„é›²ç«¯æ•¸ä½æŒ‡ç´‹ç´€éŒ„ã€‚")

    def _load_data(self):
        """ğŸš€ å…·å‚™ç‰ˆæœ¬è‡ªå‹•å‡ç´šèƒ½åŠ›çš„æ•¸æ“šè®€å–é‚è¼¯"""
        raw_data = {
            "last_recon": {},
            "domains": {},
            "burned_identities": {},
            "github_rescue_log": [],  # ğŸš€ å°ˆé–€å­˜æ”¾ GitHub æˆåŠŸæ•‘æ´çš„æ™‚é–“æˆ³
            "scrapi_history": [],     # å­˜scrapiç¢ºä¿é€™å…©å€‹æ¬„ä½åœ¨ raw_data é ‚å±¤
            "global_failures": [],
            "server_stats": {},
            "incidents": [],
            "path_history": {},
            
            "pending_missions": [],   # ğŸš€ [ç´€éŒ„] å¾…è£œæª”ä»»å‹™æ¸…å–® ï¼Œä¸‹æ–¹é»æ•¸è¨ˆç®—
            "scrap_api_vault": {
                "current_balance": 1000.0,
                "weekly_carry_over": 0.0,
                "last_refill_date": datetime.now(timezone.utc).strftime("%Y-%m-%d")
            }
        }
        
        if os.path.exists(self.file_path):
            try:
                with open(self.file_path, "r", encoding="utf-8") as f:
                    stored = json.load(f)
                    # ğŸ’¡ é—œéµï¼šå°‡æœ¬åœ°å­˜æª”èˆ‡é è¨­çµæ§‹é€²è¡Œã€Œæ·±åº¦åˆä½µã€ï¼Œç¢ºä¿èˆŠè³‡æ–™ä¸ä¸Ÿå¤±ã€æ–°æ¬„ä½ä¸éºæ¼
                    raw_data.update(stored)
                    return raw_data
            except Exception as e:
                print(f"âš ï¸ è®€å–æª”æ¡ˆå¤±æ•—ï¼Œä½¿ç”¨é è¨­çµæ§‹: {e}")
        
        return raw_data
        
    # ğŸš€ [ISP]ï¼šä¸€è‡´æ€§æ ¡å°
    def verify_isp_consistency(self, path_id, current_org):
        """ğŸ›¡ï¸ æª¢æŸ¥ç•¶å‰ ISP æ˜¯å¦èˆ‡è©²è·¯å¾‘æ­·å²ç´€éŒ„ç›¸ç¬¦"""
        last_org = self.data.get("last_recon", {}).get("org", "Unknown")
        if last_org == "Unknown": return True
        
        return last_org[:3].upper() == current_org[:3].upper() # ä¾›æ‡‰å•†åï¼ˆå‰ä¸‰å­—ï¼‰ç›¸åŒï¼Œå°±é€šé
   
    # ==========================================================================
    # --- ğŸ›°ï¸ 1. åµå¯Ÿè„ˆè¡ç´€éŒ„é‚è¼¯ (è·¯å¾‘å¯©è¨ˆèˆ‡ ISP æ ¡å°) ---
    # ==========================================================================

        # --- é›™é‡é©—è­‰ èˆ‡ ISP ç¦è¡Œ ---
    def process_recon_data(self, recon_data, expected_path_id="A"):
        """ğŸ§  [åˆ†æ] æ¥æ”¶æ•¸æ“šä¸¦åŸ·è¡Œå¼·åŒ–ç‰ˆ ISP å¯©è¨ˆ [update: 2026-02-07]"""
        if not recon_data: return None

        try:
            current_ip = recon_data.get("ip", "?.?.?.?")
            current_org = recon_data.get("org", "Unknown")
            expected_org = PATH_CONFIG.get(expected_path_id, "Unknown")
            
            # 1. ğŸ›¡ï¸ [æ ¸å¿ƒè®Šæ›´ï¼šè² å‘è¡¨åˆ—] æª¢æŸ¥æ˜¯å¦ç‚º GitHub Runner åŸç”Ÿç’°å¢ƒ (çµ•å°ç¦æ­¢åŸ·è¡Œçš„ ISP)
            # åªè¦åµæ¸¬åˆ° Azure æˆ– Microsoftï¼Œ org_drift ç›´æ¥è¨­ç‚º 2.0 (è‡´å‘½é¢¨éšª)
            dangerous_isps = ["MICROSOFT", "AZURE", "AMAZON", "AWS", "GOOGLE-CLOUD"]
            is_leaking = any(danger in current_org.upper() for danger in dangerous_isps)
            
            # 2. ğŸ›¡ï¸ [æ­£å‘æ¯”å°]
            is_isp_legal = (expected_org.upper() in current_org.upper())
            if expected_path_id == "B" and "CLOUDFLARE" in current_org.upper():
                is_isp_legal = True 
            # ğŸ’¡ é¡å¤–ä¿éšªï¼šISP åç¨±å«æœ‰ "FLY" å­—çœ¼ï¼Œä¹Ÿåˆæ³•
            if "FLY" in current_org.upper():
                is_isp_legal = True

            # 2.5. âš–ï¸ åˆ¤å®šæ¬Šé‡ï¼š0=åˆæ ¼, 1=Unknown/æ¼‚ç§», 2=è‡´å‘½æ´©æ¼
            if is_leaking:
                org_drift = 2.0
            elif is_isp_legal or current_org == "Unknown":
                org_drift = 0.0  # å…è¨± Unknown é€²å…¥ä¸»ç¨‹å¼çš„å†æ¬¡æª¢æŸ¥é‚è¼¯
            else:
                org_drift = 1.0         

            # --- ä»¥ä¸‹ä¿ç•™åŸæœ‰çš„ recon_report å»ºç«‹é‚è¼¯ ---
            last_ip = self.get_last_known_ip(expected_path_id)
            unique_count = self.count_unique_ips(expected_path_id, current_ip)
            is_drifted = (last_ip is not None and last_ip != current_ip)

            # 3. ğŸ“œ [å»ºç«‹æ•´åˆæˆ°å ±]
            recon_report = {
                "ip": current_ip,
                "org": current_org,
                "is_leaking": is_leaking,        # ğŸš€æ–¹ä¾¿é™¤éŒ¯ 
                "gateway_status": recon_data.get("gateway_status", "N/A"), # ğŸš€ æ‰¿æ¥ Navigator æ–°å¢çš„é–˜é“æ•¸æ“š
                "path_id": expected_path_id,
                "drift_detected": is_drifted,    # ğŸš€ IP æ˜¯å¦è®Šå‹•
                "org_drift": org_drift,          # ğŸš€ ISP æ˜¯å¦è®Šå‹•
                "unique_ip_reach": unique_count, # ğŸš€ è©²è·¯å¾‘ç›®å‰å·²ç´¯ç©å‡ºå£æ•¸
                "checked_at": datetime.now(timezone.utc).isoformat()
            }
            
            self.data["last_recon"] = recon_report
            self.save()

            if org_drift >= 2.0:
                print(f"ğŸ’€ [è‡´å‘½å‘Šè­¦] åµæ¸¬åˆ°é›²ç«¯åŸç”Ÿ IP ({current_org})ï¼èº«åˆ†å³å°‡æ›éœ²ï¼Œå¼·åˆ¶æ–·é›»ã€‚")
            elif org_drift == 1.0:
                print(f"ğŸš¨ [åš´æ­£å‘Šè­¦] è·¯å¾‘ ISP ç•°å¸¸ï¼é æœŸ: {expected_org} | å¯¦éš›: {current_org}")
            
            return recon_report
        except Exception as e:
            print(f"âŒ ç›£è¦–å™¨åµå¯Ÿåˆ†æå¤±æ•—: {e}")
            return None

    def trigger_double_check(self, nav):
        """ğŸ›°ï¸ [å‚™æ´åµå¯Ÿ] ç•¶ç¬¬ä¸€ä¾†æºç‚º Unknown æ™‚ï¼Œç”±ç¬¬äºŒ API é€²è¡Œå¼·åˆ¶æ ¸æŸ¥"""
        print("ğŸ” [å‚™æ´ç³»çµ±] ç¬¬ä¸€ä¾†æºå›å‚³ Unknownï¼Œå•Ÿå‹•å‚™æ´ API (ip.sb) é€²è¡ŒäºŒæ¬¡æ ¸æŸ¥...")
        try:
            # é€éå°èˆªå“¡çš„ Session ç™¼èµ·è«‹æ±‚ï¼Œç¢ºä¿å‡ºå£ä¸€è‡´
            resp = nav.session.get("https://api.ip.sb/geoip", timeout=15)
            if resp.status_code == 200:
                data = resp.json()
                return {
                    "ip": data.get("ip"),
                    "org": data.get("organization") or data.get("isp", "Unknown")
                }
        except:
            print("âš ï¸ [å‚™æ´ç³»çµ±] äºŒæ¬¡æ ¸æŸ¥é€£ç·šè¶…æ™‚ã€‚")
        return None
    # ==========================================================================
    # --- ğŸ“Š 2. é¢¨éšªè©•ä¼°èˆ‡ç‡’æ¯€æª¢æŸ¥ ---
    # ==========================================================================
    def get_risk_score(self, identity_hash):
        """
        ğŸ“Š è¨ˆç®—å…¬å¼ï¼šé¢¨éšªç¸½åˆ† = Î£ (å¤±æ•—æ¬Šé‡ * æ™‚é–“è¡°æ¸›)
        è¡°æ¸›ä¿‚æ•¸ï¼šä½¿ç”¨ 24 å°æ™‚åŠè¡°æœŸç­–ç•¥ (lambda=0.0288)ã€‚
        """
        now = time.time()
        # å°‡èº«ä»½ Hash æ˜ å°„åˆ° domain çµæ§‹ä¸­å„²å­˜
        i_data = self.data["domains"].get(f"id_{identity_hash}", {"failures": []})
        total_score = 0.0

        for fail in i_data["failures"]:
            t = (now - fail["timestamp"]) / 3600 # è½‰æ›ç‚ºå°æ™‚
            decay = math.exp(-self.lambda_constant * t)
            total_score += fail["weight"] * decay

        return round(total_score, 2)
    
    
    def is_identity_safe(self, identity_hash):
        """
        ğŸ›¡ï¸ è§£æ±º AttributeErrorï¼šæª¢æŸ¥èº«åˆ†æ˜¯å¦å®‰å…¨
        """
        # ç¬¬ä¸€é—œï¼šæª¢æŸ¥ 30 å¤©ç¡¬æ€§ç‡’æ¯€
        burn_time = self.data["burned_identities"].get(identity_hash)
        if burn_time:
            if (time.time() - burn_time) < 2592000: # 30å¤©
                return False
            else:
                del self.data["burned_identities"][identity_hash] # è‡ªå‹•è§£å°

        # ç¬¬äºŒé—œï¼šæª¢æŸ¥å‹•æ…‹è¡°æ¸›é¢¨éšªåˆ†
        score = self.get_risk_score(identity_hash)
        return score < 1.0

    
    def record_event(self, identity_hash, status_code, target_url=None, task_type="mission"):
        """ğŸ›¡ï¸ [æ†²å…µç´€éŒ„] åˆ†é¡è¿½è¹¤ï¼šåµå¯Ÿ(scout) èˆ‡ é‹è¼¸(mission) [cite: 2026-02-01]"""
        host = target_url.split('/')[2] if target_url else "Unknown_Host"
        
        if "server_stats" not in self.data: self.data["server_stats"] = {}
        if host not in self.data["server_stats"]:
            # ğŸ’¡ åˆ†é–‹å„²å­˜ï¼šåµå¯ŸæˆåŠŸ/å¤±æ•— èˆ‡ é‹è¼¸æˆåŠŸ/å¤±æ•—
            self.data["server_stats"][host] = {
                "scout_ok": 0, "scout_fail": 0, 
                "mission_ok": 0, "mission_fail": 0
            }

        # ç´€éŒ„æ¬¡æ•¸é‚è¼¯
        stats = self.data["server_stats"][host]
        is_ok = (status_code == 200)
        
        if task_type == "scout":
            if is_ok: stats["scout_ok"] += 1
            else: stats["scout_fail"] += 1
        else:
            if is_ok: stats["mission_ok"] += 1
            else: stats["mission_fail"] += 1

        # --- 3. [ä¿ç•™åŠŸèƒ½] æˆåŠŸè«‹æ±‚ä¸è¨ˆå…¥èº«åˆ†é¢¨éšªåˆ† - 
        if status_code == 200:
            self.save()
            return

        # --- 4. [ä¿ç•™åŠŸèƒ½] é‡å°ä¼ºæœå™¨æ‹’çµ•é€²è¡Œèº«åˆ†æ¬Šé‡æ‰£åˆ†  
        weights = {403: 1.0, 429: 0.8}
        w = weights.get(status_code, 0.2)

        id_key = f"id_{identity_hash}"
        if id_key not in self.data["domains"]:
            self.data["domains"][id_key] = {"failures": []}

        self.data["domains"][id_key]["failures"].append({
            "timestamp": time.time(),
            "code": status_code,
            "weight": w
        })

        # --- 5. [ä¿ç•™åŠŸèƒ½] 403 èº«åˆ†ç‡’æ¯€æ©Ÿåˆ¶  
        if status_code == 403:
            print(f"ğŸ”¥ [è­¦å‘Š] èº«åˆ†æ›å…‰ ({identity_hash})ï¼å•Ÿå‹• 30 å¤©ç‡’æ¯€ã€‚")
            self.data["burned_identities"][identity_hash] = time.time()
        
        self.save()

    
    # ==========================================================================
    # --- ğŸ“¦ 2.5 æ•¸æ“šæ­¸æª”ç³»çµ± (å°é½Šé€±æ—¥çµç®—) [cite: 2026-02-03] ---
    # ==========================================================================

    def finalize_weekly_archive(self, week_label):
        """ğŸ“¦ [æˆ°ç•¥å°å­˜] ç´å…¥è·¯å¾‘æ­·å²æ•¸æ“šï¼Œä¾›æœˆå ±åˆ†æ IP å£½å‘½ [cite: 2026-02-03]"""
        archive_data = {
            "week": week_label,
            "timestamp": time.time(),
            "performance_summary": self.data.get("performance_map", {}),
            "incident_logs": self.data.get("incidents", []),
            "server_stats": self.data.get("server_stats", {}),
            # ğŸš€  ç´€éŒ„æœ¬é€±çµæŸæ™‚å„è·¯å¾‘çš„ IP å±¥æ­· [02/03]
            "path_stability": self.data.get("path_history", {}) 
        }
        
        print(f"ğŸ“ [ç›£è¦–å™¨] åŒ…å«è·¯å¾‘æ­·å²çš„é€±å¿«ç…§å·²ç”Ÿæˆï¼š{week_label}")
        
        # ğŸ’¡ è¨»ï¼špath_history ä¸æ­¸é›¶ï¼Œå› ç‚ºå®ƒæ˜¯è·¨é€±çš„èº«åˆ†ç´¯ç©æŒ‡æ¨™
        self.data["incidents"] = []
        self.save()
        return archive_data 

    # ==========================================================================
    # --- ğŸ“Š 3. æˆ°ç•¥å½™æ•´å ±å‘Š (å°é½Š 7 å¤©å‘¨åˆ¶) ---
    # ==========================================================================
    def get_weekly_summary(self):
        """ğŸ“Š ç”¢ç”Ÿé€±æˆ°ç•¥å ±å‘Š (å«æ·±åº¦å–è­‰æƒ…å ±) [cite: 2026-02-03]"""
        report = "ğŸ“… **Info Commander é€±æˆ°ç•¥æˆ°å ±**\n"
        report += "--------------------------------\n"
        
        # A. éƒ¨éšŠé¢¨éšªè©•ä¼° (Identity Risk)
        report += "ğŸ›¡ï¸ **éƒ¨éšŠç‹€æ…‹ (Identity Risk):**\n"
        for id_key in self.data.get("domains", {}):
            h = id_key.replace("id_", "")
            score = self.get_risk_score(h)
            status = "ğŸŸ¢ å®‰å…¨" if score < 0.5 else ("ğŸŸ¡ è­¦æˆ’" if score < 1.0 else "ğŸ”´ æš´éœ²")
            report += f" - {id_key[:12]}.. : {status} ({score})\n"
        
        # B. ä¼ºæœå™¨æ’è¡Œæ¦œ (åˆ†é–‹å‘ˆç¾åµå¯Ÿèˆ‡é‹è¼¸)
        report += "\nğŸ“¡ **ä¼ºæœå™¨åˆ†é …çµ±è¨ˆ (Recon vs Mission):**\n"
        server_stats = self.data.get("server_stats", {})
        if not server_stats:
            report += " (æš«ç„¡ç´€éŒ„)\n"
        else:
            for host, s in server_stats.items():
                report += f"ğŸ“ {host}:\n"
                report += f"  - åµå¯Ÿ(Scout): {s.get('scout_ok', 0)}é€š / {s.get('scout_fail', 0)}æ‹’\n"
                report += f"  - é‹è¼¸(Mission): {s.get('mission_ok', 0)}é€š / {s.get('mission_fail', 0)}æ‹’\n"

        # C. ğŸ”¥ ç•°å¸¸äº‹ä»¶å–è­‰å ±å‘Š (Forensics)-å­¸ç¿’ä¼ºæœå™¨é˜²ç¦¦é‚è¼¯çš„æ ¸å¿ƒ
        report += "\nğŸš¨ **ç•°å¸¸äº‹ä»¶å–è­‰ (Recent Incidents):**\n"
        incidents = self.data.get("incidents", [])
        if not incidents:
            report += " âœ… æœ¬é€±ç„¡ 403 æ””æˆªäº‹ä»¶ã€‚\n"
        else:
            for i, inc in enumerate(incidents[:5], 1): # å ±è¡¨åƒ…åˆ—å‡ºæœ€è¿‘ 5 ç­†
                diag = inc.get("diagnostics", {})
                report += f"{i}. ğŸ¯ ç›®æ¨™: {inc['host']}\n"
                report += f"   ğŸ•µï¸ åˆ¤å®š: IPä¿¡è­½ [{diag.get('ip_reputation', 'N/A')}] | å°é”æ·±åº¦ [{diag.get('ban_depth', 'N/A')}]\n"
                report += f"   ğŸ•’ æ™‚é–“: {inc.get('iso_time', 'N/A')[:19]}\n"
        
        # D. ğŸš€  è·¯å¾‘ç©©å®šæ€§åˆ†æ (Path Stability)
        report += "\nğŸŒ **è·¯å¾‘ç©©å®šæ€§åˆ†æ (Path Stability):**\n"
        path_history = self.data.get("path_history", {})
        
        if not path_history:
            report += " âœ… æ‰€æœ‰è·¯å¾‘å‡ºå£ä¿æŒç©©å®šã€‚\n"
        else:
            for pid, ips in path_history.items():
                unique_count = len(set(ips))
                # ğŸ’¡ åˆ¤å®šç©©å®šåº¦ï¼šå‡ºå£æ„ˆå¤šæ„ˆä¸ç©©å®š
                stability_icon = "ğŸŸ¢ ç©©å®š" if unique_count < 3 else ("ğŸŸ¡ æ³¢å‹•" if unique_count < 7 else "ğŸ”´ æ··äº‚")
                report += f" - è·¯å¾‘ {pid} : {stability_icon} (ç´¯ç©å‡ºå£æ•¸: {unique_count})\n"
                if ips:
                    report += f"   â””â”€ ç›®å‰å‡ºå£: {mask_ip(ips[0])}\n"
        
  
        return report
    